{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae4721fa-2504-4a24-a344-c087b7103058",
   "metadata": {},
   "source": [
    "# Experimentos en el escenario de cruce\n",
    "\n",
    "Cargamos librerías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4ffb3-d42f-43c3-b8f3-62c008130c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "from navground import core, sim\n",
    "\n",
    "plots_dir = os.path.join(\"plots\", \"realistic\")\n",
    "experiment_dir = \"experiments\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(\"experiments\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bafc77f-dbc6-425c-8b56-8023d8506bb3",
   "metadata": {},
   "source": [
    "Ejecutamos los experimentos y los guardamos en ficheros .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbe240f-cd6f-4e97-8f4d-b1f67e517b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross\n",
    "side = 5\n",
    "num_steps = 300\n",
    "num_runs = 12\n",
    "tolerance = 0.5 # Tolerance to target in Cross\n",
    "behaviour_list = [\"ORCA\", \"HL\", \"HRVO\", \"Dummy\"]\n",
    "marker_behaviour = {\"ORCA\": \"o\", \"HL\": \"X\", \"HRVO\": \"+\", \"Dummy\": \"*\"}\n",
    "color_behaviour = {}\n",
    "for i, behaviour in enumerate(behaviour_list):\n",
    "    color_behaviour[behaviour] = mpl.colormaps[\"Set1\"](i / (len(behaviour_list) +1))\n",
    "for behaviour in behaviour_list:\n",
    "    path = os.path.join(experiment_dir, f\"realistic_{behaviour}.h5\")\n",
    "    yaml = f\"\"\"\n",
    "    steps: {num_steps}\n",
    "    time_step: 0.1\n",
    "    record_pose: true\n",
    "    record_twist: true\n",
    "    runs: {num_runs}\n",
    "    record_collisions: true\n",
    "    record_deadlocks: true\n",
    "    record_safety_violation: true\n",
    "    record_efficacy: true\n",
    "    terminated_when_idle_or_stuck: false\n",
    "    scenario:\n",
    "      type: Cross \n",
    "      side: {side} \n",
    "      tolerance: {tolerance}\n",
    "      groups:\n",
    "        - number: 10\n",
    "          type: human\n",
    "          radius:\n",
    "            sampler: uniform\n",
    "            from: 0.15\n",
    "            to: 0.3\n",
    "          color: blue\n",
    "          kinematics:\n",
    "            type: Ahead\n",
    "            max_speed: 1.5\n",
    "            max_angular_speed: 3.0\n",
    "          behavior:\n",
    "            type: HL\n",
    "            optimal_speed: \n",
    "              sampler: uniform\n",
    "              from: 0.7\n",
    "              to: 1.2\n",
    "        - number: 2\n",
    "          type: wheelchair\n",
    "          color: red\n",
    "          radius: 0.4\n",
    "          kinematics:\n",
    "            type: 2WDiff\n",
    "            wheel_axis: 0.6\n",
    "            max_speed: 1.2\n",
    "          behavior:\n",
    "            type: {behaviour}\n",
    "          state_estimation:\n",
    "            type: Bounded\n",
    "            range: 5.0\n",
    "    \"\"\"\n",
    "    experiment = sim.load_experiment(yaml)\n",
    "    experiment.run(keep=False, data_path=path)\n",
    "    del experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee11ca-382d-4137-a4cb-29358055f3c0",
   "metadata": {},
   "source": [
    "Cargamos los experimentos y los guardamos en un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c26e3f-2307-4b2c-bbcb-b333a011595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {}\n",
    "# Reload simulations\n",
    "for behaviour in behaviour_list:\n",
    "    path = os.path.join(experiment_dir, f\"realistic_{behaviour}.h5\")\n",
    "    recorded_experiment = sim.RecordedExperiment(path)\n",
    "    runs[behaviour] = recorded_experiment.runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce89505b-82a3-4bc4-b994-306822509d42",
   "metadata": {},
   "source": [
    "Visualizamos alguna ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686f4ce4-a920-4cb2-9234-e902f3fa508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navground.sim.ui import WebUI\n",
    "from navground.sim.notebook import notebook_view\n",
    "from navground.sim.replay import RealTimeReplay\n",
    "\n",
    "web_ui = WebUI(host='127.0.0.1', max_rate=-1)\n",
    "await web_ui.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f826ec-1611-4f66-87f9-fc67b5631802",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_view(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea4191-4dcf-421c-b48a-d44accaab3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_sim = RealTimeReplay(run=runs[\"ORCA\"][0], factor=3, web_ui=web_ui)\n",
    "await rt_sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6266fcd-1138-4889-beb5-feea317ef487",
   "metadata": {},
   "source": [
    "Funciones para medir deadlocks, colisiones y eficacia (provenientes de una libreta de Jerome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca73332-98b0-4f51-bd20-77678d6267e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_deadlocks(deadlock_time, initial_time, final_time):\n",
    "    is_deadlocked = np.logical_and(deadlock_time > initial_time, deadlock_time < (final_time - 5.0))\n",
    "    return sum(is_deadlocked)\n",
    "\n",
    "def extract_data(experiment, initial_step, final_step):\n",
    "    collisions = []\n",
    "    deadlocks = []\n",
    "    efficacy = []\n",
    "    sms = []\n",
    "    seeds = []\n",
    "    for i, run in experiment.runs.items():\n",
    "        world = run.world\n",
    "        initial_time, final_time = initial_step*run.time_step, final_step*run.time_step\n",
    "        deadlocks.append(count_deadlocks(np.array(run.deadlocks), initial_time, final_time))\n",
    "        collisions.append(np.sum(np.logical_and(\n",
    "            initial_step < run.collisions[:,0], run.collisions[:,0] < final_step\n",
    "        )))\n",
    "        efficacy.append(np.array(run.efficacy[initial_step:final_step]).mean())\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'deadlocks': deadlocks,\n",
    "        'collisions': collisions,\n",
    "        'efficacy': efficacy})\n",
    "    df['safe'] = (df.collisions == 0).astype(int)\n",
    "    df['fluid'] = (df.deadlocks == 0).astype(int)\n",
    "    df['ok'] = ((df.deadlocks == 0) & (df.collisions == 0)).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b1458-7fec-4219-a0f5-1969318e45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list = list(range(40, num_steps, 5))\n",
    "initial_step = steps_list[0]\n",
    "final_step = steps_list[-1]\n",
    "deadlocks = {}\n",
    "collisions = {}\n",
    "efficacy = {}\n",
    "for behaviour in behaviour_list:\n",
    "    path = os.path.join(experiment_dir, f\"realistic_{behaviour}.h5\")\n",
    "    recorded_experiment = sim.RecordedExperiment(path)\n",
    "    df = extract_data(recorded_experiment, initial_step, final_step)\n",
    "    collisions[behaviour] =  list(df.collisions)\n",
    "    deadlocks[behaviour] = list(df.deadlocks)\n",
    "    efficacy[behaviour] = list(df.efficacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377c66c-250b-4b9d-8884-003af58dbfce",
   "metadata": {},
   "source": [
    "Visualizamos los rendimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e461f-cd70-44d6-817f-a14d77ce030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4), ncols=3)\n",
    "for behaviour in behaviour_list:\n",
    "    ax[0].scatter(deadlocks[behaviour], collisions[behaviour], color=color_behaviour[behaviour], label=behaviour)\n",
    "    ax[0].set_xlabel(\"deadlocks\")\n",
    "    ax[0].set_ylabel(\"collisions\")\n",
    "    ax[1].scatter(efficacy[behaviour], collisions[behaviour], color=color_behaviour[behaviour], label=behaviour)\n",
    "    ax[1].set_xlabel(\"efficacy\")\n",
    "    ax[1].set_ylabel(\"collisions\")\n",
    "    ax[2].scatter(efficacy[behaviour], deadlocks[behaviour], color=color_behaviour[behaviour], label=behaviour)\n",
    "    ax[2].set_xlabel(\"efficacy\")\n",
    "    ax[2].set_ylabel(\"deadlocks\")\n",
    "# end for\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.3,0),  ncol=len(behaviour_list))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.sep.join((plots_dir, \"efficiency_collisions_cross.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a05fe24-2503-47fb-9c6b-2d755b779fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
