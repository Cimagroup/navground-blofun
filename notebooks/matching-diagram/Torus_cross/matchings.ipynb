{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9879a0e4-f0bd-48e3-87db-092ea749bffb",
   "metadata": {},
   "source": [
    "# CrossTorus experiments\n",
    "\n",
    "In this notebook, we study matching diagrams across Navground simulations on the cross torus. In particular, we compare four different navigation behaviours: ORCA, HRVO, HL, SocialForce and Dummy\n",
    "\n",
    "First, let us import a few important modules for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c8bd7-8e52-4a75-a075-fc49590a0817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import os\n",
    "\n",
    "from navground import core, sim\n",
    "from navground.sim.ui.video import display_video_from_run\n",
    "\n",
    "import perdiver.perdiver as perdiver\n",
    "from perdiver.navground_io import parser, run_navground\n",
    "from perdiver.distances import *\n",
    "\n",
    "plots_dir = os.path.join(\"plots\", \"matchings\")\n",
    "experiment_dir = \"experiments\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(experiment_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a59cb6-8e89-47aa-8e75-91e7c41702b8",
   "metadata": {},
   "source": [
    "Next, let us execute the Navground cross torus experiment. We run the experiment 15 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd5d27-a69b-4176-b5ec-6ebbb2c2c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([\n",
    "        '--scenario', 'CrossTorus',\n",
    "        '--side', '6.5',\n",
    "        '--num_runs', '15',\n",
    "        '--num_steps', '500',\n",
    "        '--time_step', '0.1',\n",
    "        '--num_agents', '12',\n",
    "        '--max_speed', '1.66',\n",
    "        '--optimal_speed_min', '0.1',\n",
    "        '--optimal_speed_min', '0.15',\n",
    "        '--radius', '0.4',\n",
    "        '--safety_margin', '0.1',\n",
    "        '--epsilon', '20',\n",
    "        '--time_delay', '5',\n",
    "])\n",
    "behavior_list = [\"ORCA\", \"HL\", \"HRVO\", \"SocialForce\"]\n",
    "runs = {}\n",
    "for behavior in behavior_list:\n",
    "    args.behavior = behavior\n",
    "    runs[behavior] = run_navground(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a466b7a5-9065-4c22-8e5d-e8f563845ffa",
   "metadata": {},
   "source": [
    "First, let us visualise the HL experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8482f08-f1c5-4133-8e14-4a27aeeeff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video_from_run(run=runs[\"HL\"][0], factor=6.0, fps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e2ea2-f58e-40db-b452-2e2c97235ceb",
   "metadata": {},
   "source": [
    "Now, we visualise the ORCA experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4f69c-c861-4b3e-a8a1-e010f51faa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video_from_run(run=runs[\"ORCA\"][0], factor=6.0, fps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1332c-e769-45bc-bb2f-af005428b09c",
   "metadata": {},
   "source": [
    "Also HRVO and Dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee86a27-6aa1-4ce3-bf60-ddbcc3c1ff45",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video_from_run(run=runs[\"HRVO\"][0], factor=6.0, fps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb89e1-e57c-4f99-87e8-05d0fc108f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_video_from_run(run=runs[\"SocialForce\"][0], factor=6.0, fps=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0e84c-57ad-4b9c-88ef-88562ff00354",
   "metadata": {},
   "source": [
    "Both simulations are very different. In partiuclar, we observe mainly two dynamics, either the robots end up going in straight trajectories or they get stuck. Both examples below where produced with the same variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d68f9f-561a-4aa2-8322-bf4499bdc83e",
   "metadata": {},
   "source": [
    "### Pairwise Matchings\n",
    "\n",
    "We are now going to compute the induced matchings and their associated diagrams.\n",
    "\n",
    "Also, we set up the variable \"weight\" and the timestep shift for our experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466df9ac-dc97-4f44-af56-e0f25652918b",
   "metadata": {},
   "source": [
    "Now, we are going to start by considering two timesteps and their associated divergence diagrams. Notice that these do not change much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0e2e2-cef5-480d-8bbc-b9a636a1cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perdiver.distances import  distances_2Dtorus_weighted_velocities\n",
    "from perdiver.perdiver import get_matching_diagram\n",
    "from perdiver.perdiver import plot_timesteps_cross_torus, plot_matching_diagram, same_diagram_scale\n",
    "\n",
    "args.weight = 1\n",
    "args.start_step = 20\n",
    "gs_kw = dict(width_ratios=[1,1], height_ratios=[1,1])\n",
    "sb = [\"HL\", \"ORCA\"]\n",
    "fig, axd = plt.subplot_mosaic([[f'points_{sb[0]}', f'Diag_{sb[0]}'],\n",
    "                               [f'points_{sb[1]}', f'Diag_{sb[1]}']],\n",
    "                              gridspec_kw=gs_kw, figsize=(8, 8),\n",
    "                              layout=\"constrained\")\n",
    "for behavior in sb:\n",
    "    run = runs[behavior][0]\n",
    "    ps = np.array(run.poses)\n",
    "    twists = np.array(run.twists)\n",
    "    X = ps[args.start_step]\n",
    "    Y = ps[args.start_step + args.epsilon]\n",
    "    vel_X = twists[args.start_step]\n",
    "    vel_Y = twists[args.start_step + args.epsilon]\n",
    "    X_len = X.shape[0]-1\n",
    "    # Plot two timesteps\n",
    "    ax = axd[f\"points_{behavior}\"]\n",
    "    plot_timesteps_cross_torus(run, [args.start_step, args.start_step + args.epsilon], args.side, ax) \n",
    "    ax.set_title(f\"points_{behavior}\", fontsize=20)\n",
    "    # Plot matching diagram\n",
    "    ax = axd[f\"Diag_{behavior}\"]\n",
    "    Dist_X = distances_2Dtorus_weighted_velocities(X, vel_X, args.weight, args.side)\n",
    "    Dist_Y = distances_2Dtorus_weighted_velocities(Y, vel_Y, args.weight, args.side)\n",
    "    match_diagram = get_matching_diagram(Dist_X, Dist_Y)\n",
    "    plot_matching_diagram(match_diagram, ax, color=\"blue\")\n",
    "    ax.set_title(behavior, fontsize=20)\n",
    "# end for\n",
    "same_diagram_scale([axd[f'Diag_{sb[0]}'], axd[f'Diag_{sb[1]}']])\n",
    "plt.savefig(os.path.join(plots_dir, f\"two_timesteps_cross_torus_{sb[0]}_{sb[1]}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e061f9-7935-4a32-9159-0112beb69708",
   "metadata": {},
   "source": [
    "Last, we compute the persistence matching diagrams across behaviours, runs and step list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52910f46-e820-4fb2-990a-2fdd520b7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as dist\n",
    "\n",
    "args.steps_list = list(range(0, args.num_steps-args.epsilon-args.time_delay, args.time_delay))\n",
    "args.weight = 2\n",
    "\n",
    "diagrams_behavior = {}\n",
    "for j, behavior in enumerate(behavior_list):\n",
    "    diagrams_run_list = []\n",
    "    for i_run in range(args.num_runs):\n",
    "        ps = np.array(runs[behavior][i_run].poses)\n",
    "        twists = np.array(runs[behavior][i_run].twists)\n",
    "        diagrams_list = []\n",
    "        for idx, start_step in enumerate(args.steps_list):\n",
    "            if ps.shape[0] > start_step + args.epsilon:\n",
    "                X = ps[start_step]\n",
    "                Y = ps[start_step + args.epsilon]\n",
    "                vel_X = twists[start_step]\n",
    "                vel_Y = twists[start_step + args.epsilon]\n",
    "                Dist_X = distances_2Dtorus_weighted_velocities(X, vel_X, args.weight, args.side)\n",
    "                Dist_Y = distances_2Dtorus_weighted_velocities(Y, vel_Y, args.weight, args.side)\n",
    "                match_diagram = perdiver.get_matching_diagram(Dist_X, Dist_Y)\n",
    "                diagrams_list.append(match_diagram)\n",
    "            else: # Add matching diagram from previus loop\n",
    "                diagrams_list.append(match_diagram)\n",
    "\n",
    "        # end for over start steps\n",
    "        diagrams_run_list.append(np.array(diagrams_list))\n",
    "    # end for over runs\n",
    "    diagrams_behavior[behavior] = diagrams_run_list\n",
    "# end for over behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e7cfe-7822-4def-b6c5-cf2337d0d5c3",
   "metadata": {},
   "source": [
    "Next, we plot the evolution of such diagrams for the behaviours, on the first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b035e3-dd9d-42cb-a473-6fc55e8ba6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=len(behavior_list), figsize=(5*len(behavior_list),4))\n",
    "for j, behavior in enumerate(behavior_list):\n",
    "    diagrams_run = diagrams_behavior[behavior][0] # Take first run only\n",
    "    for idx, start_step in enumerate(args.steps_list):\n",
    "        perdiver.plot_matching_diagram(diagrams_run[idx], ax[j], color=mpl.colormaps[\"GnBu\"](idx/len(args.steps_list)))\n",
    "    # end for \n",
    "    norm = mpl.colors.Normalize(vmin=args.steps_list[0], vmax=args.steps_list[-1])\n",
    "    cmap = mpl.colormaps[\"GnBu\"]\n",
    "    mappable = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    plt.colorbar(mappable=mappable, ax=ax[j])\n",
    "    ax[j].set_title(f\"Evolution matching diagram {behavior}\")\n",
    "# end for\n",
    "perdiver.same_diagram_scale([ax[i] for i in range(4)])\n",
    "plt.savefig(os.path.join(plots_dir, f\"evolution_matching_behaviors.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab95a71f-7863-4d43-97cf-5cd93066bf7c",
   "metadata": {},
   "source": [
    "## Vectorisations of matching diagrams\n",
    "\n",
    "### Vectorisation 1: timestep means of persistence images\n",
    "\n",
    "We vectorise the persistence diagrams using persistence images. In particular, for each run, we obtain a single image given by taking the mean across the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68ca0b-99c1-411c-8636-37105bdaa050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gudhi import representations\n",
    "\n",
    "npixels = 15\n",
    "perim = representations.PersistenceImage(resolution=[npixels, npixels], bandwidth=0.1, im_range=[0,3,-3,3])\n",
    "### Put together all persistence diagrams for fitting persistence images\n",
    "all_diagrams = []\n",
    "for behavior in behavior_list:\n",
    "    for i_run in range(args.num_runs): \n",
    "        for matching_diagram in diagrams_behavior[behavior][i_run]:\n",
    "            all_diagrams.append(matching_diagram)\n",
    "        # for over matching diagrams from run\n",
    "    # for over runs\n",
    "# for over behaviors\n",
    "perim.fit(all_diagrams)\n",
    "### Compute persistence images for all behaviors and runs\n",
    "perim_arr_dict = {}\n",
    "for behavior in behavior_list:\n",
    "    perim_means_list = []\n",
    "    for i_run in range(args.num_runs): \n",
    "        perim_means_list.append(perim.transform(diagrams_behavior[behavior][i_run]))\n",
    "    # end for\n",
    "    perim_arr_dict[behavior] = perim_means_list\n",
    "# end for\n",
    "### Compute means across timesteps of persistence images for all behaviors and runs\n",
    "perim_means = {}\n",
    "for behavior in behavior_list:\n",
    "    perim_means_list = []\n",
    "    for i_run in range(args.num_runs): \n",
    "        perim_means_list.append(perim_arr_dict[behavior][i_run].mean(axis=0).reshape(15,15))\n",
    "    # end for over runs\n",
    "    perim_means[behavior] = perim_means_list\n",
    "# end for over behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa3b14-84d3-4d41-978a-8434941a5c78",
   "metadata": {},
   "source": [
    "Visualise persistence images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b682f-4182-4502-9fd4-13169ba0ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=len(behavior_list), figsize=(3.5*len(behavior_list),3), layout=\"constrained\")\n",
    "for idx, behavior in enumerate(behavior_list):\n",
    "    perim = perim_means[behavior][0] # only take the first run\n",
    "    ax[idx].imshow(perim)\n",
    "    ax[idx].set_title(behavior, fontsize=20)\n",
    "# end for \n",
    "# plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, f\"persistence_images_means.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944a06b4-fb90-40df-968e-c8e601c590ba",
   "metadata": {},
   "source": [
    "Use PCA to detect clusters of persistence images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6a3de-b8db-40f0-af27-215ffa2a4e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_behavior = {}\n",
    "for i, behavior in enumerate(behavior_list):\n",
    "    color_behavior[behavior] = mpl.colormaps[\"Set1\"](i / (len(behavior_list) +1))\n",
    "# end for\n",
    "marker_behavior = {\"ORCA\": \"o\", \"HL\": \"X\", \"HRVO\": \"+\", \"Dummy\": \"*\", \"SocialForce\": \"x\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241ae8f-0882-4ec1-9135-79a555ff41a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Start by ransforming all persistence images into vectors\n",
    "all_perim_transformed = []\n",
    "for i, behavior in enumerate(behavior_list):\n",
    "    for image in perim_means[behavior]:\n",
    "        image_transformed = image.reshape((npixels,npixels))\n",
    "        all_perim_transformed.append(image_transformed.ravel())\n",
    "    # end for over runs\n",
    "# for over behaviors\n",
    "\n",
    "# Create and fit PCA to image persistence means, transforming to 2 d\n",
    "pca = PCA(n_components=2)\n",
    "Y = pca.fit_transform(all_perim_transformed)\n",
    "# Separate projections by behavior\n",
    "Y_dict = {}\n",
    "for i, behavior in enumerate(behavior_list):\n",
    "    Y_dict[behavior] = Y[args.num_runs*i:args.num_runs*(i+1)]\n",
    "# end for\n",
    "# Plot PCA projections\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "for behavior in behavior_list:\n",
    "    ax.scatter(Y_dict[behavior][:,0], Y_dict[behavior][:,1], color=color_behavior[behavior], label=behavior, marker=marker_behavior[behavior])\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.1,0),  ncol=len(behavior_list))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"PCA-persim-means.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d73eb-cd49-402a-91ef-8bf435614133",
   "metadata": {},
   "source": [
    "### Vectorisation 2: persistence divergence images (perdiver images)\n",
    "\n",
    "Next, we compute and print the divergence array across a few simulation steps. Basically, a persistence divergence image is an array where the horizontal axes goes along timesteps, while the vertical axes has the size the total number of agents. For each column in the array, we include the divergence scores sorted, from lower to higher.\n",
    "\n",
    "To start, we compute divergence vectors from the matching diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c02b5-b69f-43a4-bdf0-27b3294ba047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perdiver.perdiver import compute_divergence_vector\n",
    "\n",
    "divergence_dict = {}\n",
    "for behavior in behavior_list:\n",
    "    divergence_runs = []\n",
    "    for i_run in range(args.num_runs):\n",
    "        divergence_list = [] \n",
    "        for matching_diagram in diagrams_behavior[behavior][i_run]:\n",
    "            divergence_vector = np.sort(compute_divergence_vector(matching_diagram))\n",
    "            divergence_list.append(divergence_vector)\n",
    "        # for over matching diagrams from run\n",
    "        divergence_runs.append(np.array(divergence_list).transpose())\n",
    "    # for over runs\n",
    "    divergence_dict[behavior] = divergence_runs\n",
    "# for over behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9187316f-2c42-40ec-a713-95848dff67de",
   "metadata": {},
   "source": [
    "Next, we plot some of the divergence images for illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b5753-b88e-4c8c-b7de-28ebdee48354",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = np.max([np.max(divergence_dict[behavior]) for behavior in divergence_dict.keys()])\n",
    "vmin = np.min([np.min(divergence_dict[behavior]) for behavior in divergence_dict.keys()])\n",
    "for behavior in divergence_dict.keys():\n",
    "    divergence_arr = divergence_dict[behavior][0]\n",
    "    ## Save figure \n",
    "    fig, ax = plt.subplots(figsize=(6,1.4))\n",
    "    mapable = ax.imshow(divergence_arr, aspect=\"auto\", vmax=vmax, vmin=vmin, extent=(args.steps_list[0], args.steps_list[-1], 0, X.shape[0]))\n",
    "    ax.set_title(f\"Divergence {behavior}\")\n",
    "    plt.colorbar(mapable)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plots_dir, f\"perdiver_images_{behavior}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d395be-c112-496a-abbd-fa226d842968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by ransforming all perdiver images into vectors\n",
    "perdiver_im_transformed = []\n",
    "for i, behavior in enumerate(behavior_list):\n",
    "    for image in divergence_dict[behavior]:\n",
    "        perdiver_im_transformed.append(image.ravel())\n",
    "    # end for over runs\n",
    "# for over behaviors\n",
    "\n",
    "# Create and fit PCA to image persistence means, transforming to 2 d\n",
    "pca = PCA(n_components=2)\n",
    "Y = pca.fit_transform(perdiver_im_transformed)\n",
    "# Separate projections by behavior\n",
    "Y_dict = {}\n",
    "for i, behavior in enumerate(behavior_list):\n",
    "    Y_dict[behavior] = Y[args.num_runs*i:args.num_runs*(i+1)]\n",
    "# end for\n",
    "color_behavior = {}\n",
    "for i, behavior in enumerate(behavior_list):\n",
    "    color_behavior[behavior] = mpl.colormaps[\"Set1\"](i / (len(behavior_list) +1))\n",
    "# Plot PCA projections\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "for behavior in behavior_list:\n",
    "    ax.scatter(Y_dict[behavior][:,0], Y_dict[behavior][:,1], color=color_behavior[behavior], label=behavior, marker=marker_behavior[behavior])\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.1,0),  ncol=len(behavior_list))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"PCA-perdiver-images.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01a466d-19b7-414f-98e9-ae07b1cce571",
   "metadata": {},
   "source": [
    "### Vectorisation 3: (absolute) persistence divergence\n",
    "\n",
    "We perform a lineplot for each divergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da60a8a3-f131-4503-a872-4d19191b2d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from perdiver.perdiver import absolute_perdiver_signal\n",
    "\n",
    "absdiver_dict = {}\n",
    "for behavior in behavior_list:\n",
    "    absdiver_runs = []\n",
    "    for i_run in range(args.num_runs):\n",
    "        absdiver_runs.append(\n",
    "            absolute_perdiver_signal(diagrams_behavior[behavior][i_run])\n",
    "        )\n",
    "    # for over runs\n",
    "    absdiver_dict[behavior] = absdiver_runs\n",
    "# for over behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf91ba-798a-4529-9d8b-47b4f6bd9223",
   "metadata": {},
   "source": [
    "Plot absdiver signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec26f3b-31fe-48c5-9a8f-26d71b7a254f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quartile_absdiver = {}\n",
    "for behavior in behavior_list:\n",
    "    absdiver_runs = np.vstack(absdiver_dict[behavior])\n",
    "    quartile_absdiver[behavior] = np.percentile(absdiver_runs, [25, 50, 75], axis=0)\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a009d985-06c7-42d6-84dd-6d2974ac5a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86400a2-b8e4-4bc6-9f9c-8167e8801265",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "for behavior in behavior_list:\n",
    "    quartile = quartile_absdiver[behavior]\n",
    "    ax.plot(args.steps_list, quartile[1], color=color_behavior[behavior], label=behavior)\n",
    "    ax.fill_between(args.steps_list, quartile[0], quartile[2], color=color_behavior[behavior], alpha=.3)\n",
    "# end plotting\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.1,0),  ncol=len(behavior_list))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"absolute-persistence-divergence.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625b5397-91eb-4667-bb15-55c033cb5811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit PCA to image persistence means, transforming to 2 d\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "absdiver_all = []\n",
    "for behavior in behavior_list:\n",
    "    absdiver_all += absdiver_dict[behavior]\n",
    "# absdiver list \n",
    "\n",
    "Y = pca.fit_transform(absdiver_all)\n",
    "# Separate projections by behavior\n",
    "Y_dict = {}\n",
    "for i, behavior in enumerate(behavior_list):\n",
    "    Y_dict[behavior] = Y[args.num_runs*i:args.num_runs*(i+1)]\n",
    "# end for\n",
    "color_behavior = {}\n",
    "for i, behavior in enumerate(behavior_list):\n",
    "    color_behavior[behavior] = mpl.colormaps[\"Set1\"](i / (len(behavior_list) +1))\n",
    "# Plot PCA projections\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "for behavior in behavior_list:\n",
    "    ax.scatter(Y_dict[behavior][:,0], Y_dict[behavior][:,1], color=color_behavior[behavior], label=behavior, marker=marker_behavior[behavior])\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.1,0),  ncol=len(behavior_list))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(plots_dir, \"PCA-perdiver-images.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a41f0-af45-4263-85c6-2b4aa84cece8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
