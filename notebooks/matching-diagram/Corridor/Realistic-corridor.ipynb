{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28d33b22-4db5-4a02-adf9-0b267a2c7cec",
   "metadata": {},
   "source": [
    "# Experimentos en el pasillo\n",
    "\n",
    "Load modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c52ce1f-e806-4b1a-9c46-865372fa8fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "\n",
    "import perdiver.perdiver as perdiver\n",
    "\n",
    "from navground import core, sim\n",
    "\n",
    "plots_dir = os.path.join(\"plots\", \"realistic\")\n",
    "experiment_dir = \"experiments\"\n",
    "os.makedirs(plots_dir, exist_ok=True)\n",
    "os.makedirs(\"experiments\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff384c79-f353-4765-90a6-9ea45018c600",
   "metadata": {},
   "source": [
    "Ejecutamos los experimentos y los guardamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d08ee4-aac5-4272-ac27-37fbcb494842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small Corridor\n",
    "length = 15\n",
    "width=1.8\n",
    "# Large Corridor\n",
    "# width=1.5\n",
    "# length = 15.0\n",
    "num_steps = 300\n",
    "num_runs = 12\n",
    "behaviour_list = [\"ORCA\", \"HL\", \"Dummy\", \"SocialForce\"]\n",
    "marker_behaviour = {\"ORCA\": \"o\", \"HL\": \"X\", \"Dummy\": \"*\", \"SocialForce\": \"x\"}\n",
    "color_behaviour = {}\n",
    "for i, behaviour in enumerate(behaviour_list):\n",
    "    color_behaviour[behaviour] = mpl.colormaps[\"Set1\"](i / (len(behaviour_list) +1))\n",
    "for behaviour in behaviour_list:\n",
    "    path = os.path.join(experiment_dir, f\"realistic_{behaviour}.h5\")\n",
    "    yaml = f\"\"\"\n",
    "    steps: {num_steps}\n",
    "    time_step: 0.1\n",
    "    record_pose: true\n",
    "    record_twist: true\n",
    "    runs: {num_runs}\n",
    "    record_collisions: true\n",
    "    record_deadlocks: true\n",
    "    record_safety_violation: true\n",
    "    record_efficacy: true\n",
    "    terminated_when_idle_or_stuck: false\n",
    "    scenario:\n",
    "      type: Corridor\n",
    "      length: {length}\n",
    "      width: {width} \n",
    "      groups:\n",
    "        - number: 10\n",
    "          type: human\n",
    "          radius:\n",
    "            sampler: uniform\n",
    "            from: 0.15\n",
    "            to: 0.3\n",
    "          color: blue\n",
    "          kinematics:\n",
    "            type: Ahead\n",
    "            max_speed: 1.5\n",
    "            max_angular_speed: 3.0\n",
    "          behavior:\n",
    "            type: HL\n",
    "            optimal_speed: \n",
    "              sampler: uniform\n",
    "              from: 0.7\n",
    "              to: 1.2\n",
    "        - number: 3\n",
    "          type: wheelchair\n",
    "          color: red\n",
    "          radius: 0.4\n",
    "          kinematics:\n",
    "            type: 2WDiff\n",
    "            wheel_axis: 0.6\n",
    "            max_speed: 1.2\n",
    "          behavior:\n",
    "            type: {behaviour}\n",
    "          state_estimation:\n",
    "            type: Bounded\n",
    "            range: 5.0\n",
    "    \"\"\"\n",
    "    experiment = sim.load_experiment(yaml)\n",
    "    experiment.run(keep=False, data_path=path)\n",
    "    del experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de41e2-6d4c-4b3d-b632-9888e1232a6d",
   "metadata": {},
   "source": [
    "Cargamos los experimentos que se han guardado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d5877-bedb-4869-8bde-fcafb0a96a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {}\n",
    "# Reload simulations\n",
    "for behaviour in behaviour_list:\n",
    "    path = os.path.join(experiment_dir, f\"realistic_{behaviour}.h5\")\n",
    "    recorded_experiment = sim.RecordedExperiment(path)\n",
    "    runs[behaviour] = recorded_experiment.runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16d007-e2e2-42ba-835c-e0ec09b4046e",
   "metadata": {},
   "source": [
    "Ahora podemos visualizar alguna ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa705cd-7527-4583-8e53-0732eb8c95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navground.sim.ui import WebUI\n",
    "from navground.sim.notebook import notebook_view\n",
    "from navground.sim.replay import RealTimeReplay\n",
    "\n",
    "web_ui = WebUI(host='127.0.0.1', max_rate=-1)\n",
    "await web_ui.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bab201-3b73-4bea-b1f0-6173e7bc952f",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_view(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d72e2f-6c8e-49c6-9497-e4ede6c0b160",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_sim = RealTimeReplay(run=runs[\"HL\"][3], factor=2, web_ui=web_ui)\n",
    "await rt_sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a0690-c922-42c0-9615-d783b5edbeda",
   "metadata": {},
   "source": [
    "Let us see the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff899bc-df6b-4f83-93d5-76cec45f8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_deadlocks(deadlock_time, initial_time, final_time):\n",
    "    is_deadlocked = np.logical_and(deadlock_time > initial_time, deadlock_time < (final_time - 5.0))\n",
    "    return sum(is_deadlocked)\n",
    "\n",
    "def extract_data(experiment, initial_step, final_step):\n",
    "    collisions = []\n",
    "    deadlocks = []\n",
    "    efficacy = []\n",
    "    sms = []\n",
    "    seeds = []\n",
    "    for i, run in experiment.runs.items():\n",
    "        world = run.world\n",
    "        initial_time, final_time = initial_step*run.time_step, final_step*run.time_step\n",
    "        deadlocks.append(count_deadlocks(np.array(run.deadlocks), initial_time, final_time))\n",
    "        collisions.append(np.sum(np.logical_and(\n",
    "            initial_step < run.collisions[:,0], run.collisions[:,0] < final_step\n",
    "        )))\n",
    "        efficacy.append(np.array(run.efficacy[initial_step:final_step]).mean())\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'deadlocks': deadlocks,\n",
    "        'collisions': collisions,\n",
    "        'efficacy': efficacy})\n",
    "    df['safe'] = (df.collisions == 0).astype(int)\n",
    "    df['fluid'] = (df.deadlocks == 0).astype(int)\n",
    "    df['ok'] = ((df.deadlocks == 0) & (df.collisions == 0)).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff51f3a4-491f-48ad-90d3-d1a94c5ec37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_list = list(range(40, num_steps, 5))\n",
    "initial_step = steps_list[0]\n",
    "final_step = steps_list[-1]\n",
    "deadlocks = {}\n",
    "collisions = {}\n",
    "efficacy = {}\n",
    "for behaviour in behaviour_list:\n",
    "    path = os.path.join(experiment_dir, f\"realistic_{behaviour}.h5\")\n",
    "    recorded_experiment = sim.RecordedExperiment(path)\n",
    "    df = extract_data(recorded_experiment, initial_step, final_step)\n",
    "    collisions[behaviour] =  list(df.collisions)\n",
    "    deadlocks[behaviour] = list(df.deadlocks)\n",
    "    efficacy[behaviour] = list(df.efficacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383d513-7847-4d6b-84ef-2914cd197b7a",
   "metadata": {},
   "source": [
    "Ahora visualizamos las métricas de colisión, deadlocks y eficacia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02895971-82ae-4fa7-9e2a-d617a4479194",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4), ncols=3)\n",
    "for behaviour in behaviour_list:\n",
    "    ax[0].scatter(deadlocks[behaviour], collisions[behaviour], color=color_behaviour[behaviour], label=behaviour)\n",
    "    ax[0].set_xlabel(\"deadlocks\")\n",
    "    ax[0].set_ylabel(\"collisions\")\n",
    "    ax[1].scatter(efficacy[behaviour], collisions[behaviour], color=color_behaviour[behaviour], label=behaviour)\n",
    "    ax[1].set_xlabel(\"efficacy\")\n",
    "    ax[1].set_ylabel(\"collisions\")\n",
    "    ax[2].scatter(efficacy[behaviour], deadlocks[behaviour], color=color_behaviour[behaviour], label=behaviour)\n",
    "    ax[2].set_xlabel(\"efficacy\")\n",
    "    ax[2].set_ylabel(\"deadlocks\")\n",
    "# end for\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.3,0),  ncol=len(behaviour_list))\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.sep.join((plots_dir, \"efficiency_collisions_cross.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad61b232-3cab-4494-a560-5fe0be375ece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
