{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2830c5ee-5d1e-4a54-91fa-1e677353b319",
   "metadata": {},
   "source": [
    "# Divergence Vectors on Corridor Experiment\n",
    "\n",
    "In this notebook, we run various simulations on the corridor experimetn using both HL and ORCA behaviuors.\n",
    "\n",
    "We use divergence vectors to see if these are able to distinguish between both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cee38-96e7-47c9-94c7-51ccfb6b3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.spatial.distance as dist\n",
    "import matplotlib as mpl\n",
    "\n",
    "import os\n",
    "\n",
    "from navground import core, sim\n",
    "\n",
    "import perdiver.perdiver as perdiver\n",
    "from perdiver.distances import *\n",
    "\n",
    "plots_dir = \"plots\"\n",
    "os.makedirs(plots_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a59cfcd-1e8b-464b-a5b6-47b182ccaa7d",
   "metadata": {},
   "source": [
    "We run a few times the corridor experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e7849-badc-44b9-b254-54c0a9d51f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 8.0\n",
    "num_steps = 400\n",
    "width=1.0\n",
    "num_agents = 31 # 38\n",
    "num_runs = 10\n",
    "behaviour_list = [\"ORCA\", \"HL\", \"HRVO\", \"Dummy\"]\n",
    "color_behaviour = {}\n",
    "for i, behaviour in enumerate(behaviour_list):\n",
    "    color_behaviour[behaviour] = mpl.colormaps[\"Set1\"](i / (len(behaviour_list) +1))\n",
    "for behaviour in behaviour_list:\n",
    "    path=f\"experiment_matching_finer_{behaviour}.h5\"\n",
    "    yaml = f\"\"\"\n",
    "    steps: {num_steps}\n",
    "    time_step: 0.1\n",
    "    record_pose: true\n",
    "    record_twist: true\n",
    "    record_collisions: true\n",
    "    record_deadlocks: true\n",
    "    record_safety_violation: true\n",
    "    record_efficacy: true\n",
    "    runs: {num_runs}\n",
    "    scenario:\n",
    "      type: Corridor\n",
    "      length: {length}\n",
    "      width: {width} \n",
    "      groups:\n",
    "        -\n",
    "          type: thymio\n",
    "          number: {num_agents}\n",
    "          radius: 0.08\n",
    "          control_period: 0.1\n",
    "          speed_tolerance: 0.02\n",
    "          kinematics:\n",
    "            type: 2WDiff\n",
    "            wheel_axis: 0.094\n",
    "            max_speed: 0.166\n",
    "          behavior:\n",
    "            type: {behaviour}\n",
    "            optimal_speed: 0.12\n",
    "            horizon: 5.0\n",
    "            safety_margin: 0.03\n",
    "          state_estimation:\n",
    "            type: Bounded\n",
    "            range: 5.0\n",
    "    \"\"\"\n",
    "    # optimal_speed: \n",
    "    #     sampler: normal\n",
    "    #     mean: 0.2\n",
    "    #     std_dev: 0.05\n",
    "    # horizon: 5.0\n",
    "    # safety_margin: \n",
    "    #     sampler: normal\n",
    "    #     mean: 0.08\n",
    "    #     std_dev: 0.05\n",
    "    experiment = sim.load_experiment(yaml)\n",
    "    experiment.run(keep=False, data_path=path)\n",
    "    del experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479de14b-c6f9-421a-b006-1a8d167852e7",
   "metadata": {},
   "source": [
    "We reload both experiment runs and save them into a dictionary of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c3111-ec68-4bf7-86ab-6f199cc42334",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = {}\n",
    "# Reload HL simulation\n",
    "for behaviour in behaviour_list:\n",
    "    path = f\"experiment_matching_finer_{behaviour}.h5\"\n",
    "    recorded_experiment = sim.RecordedExperiment(path)\n",
    "    runs[behaviour] = recorded_experiment.runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd95e61-de76-4cca-9012-5dc7bd8a04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestep_list = list(range(num_steps))\n",
    "# variables_behaviour = {}\n",
    "# for j, behaviour in enumerate(behaviour_list):\n",
    "#     variables_list = []\n",
    "#     for ridx in range(num_runs):\n",
    "#         variables_run = []\n",
    "#         ps = np.array(runs[behaviour][ridx].poses)\n",
    "#         twists = np.array(runs[behaviour][ridx].twists)\n",
    "#         for idx, step in enumerate(timestep_list):\n",
    "#             X = ps[step]\n",
    "#             vel_X = twists[step]\n",
    "#             variables_run.append(np.hstack((np.mean(X, axis=0), np.std(X, axis=0), np.mean(vel_X, axis=0), np.std(vel_X, axis=0))))\n",
    "#         # end for \n",
    "#         variables_list.append(np.array(variables_run).transpose())\n",
    "#     # end for\n",
    "#     variables_behaviour[behaviour] = np.array(variables_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5e36f-86ee-4b5c-b405-17d7b9114236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix_arrays_3D(A, axis=1):\n",
    "    if len(A.shape)!=3:\n",
    "        raise ValueError\n",
    "    num_elements = A.shape[axis]\n",
    "    Dist = np.zeros((num_elements, num_elements))\n",
    "    for i in range(num_elements):\n",
    "        for j in range(num_elements):\n",
    "            Dist[i,j] = np.sqrt(np.sum((A.take(i, axis=axis)-A.take(j, axis=axis))**2))\n",
    "\n",
    "    return Dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66614d7b-bc44-4e99-b08c-a054c3959f62",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738a1f91-5684-49ec-aa8e-273454981807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from navground.sim.ui import WebUI\n",
    "from navground.sim.notebook import notebook_view\n",
    "from navground.sim.replay import RealTimeReplay\n",
    "\n",
    "web_ui = WebUI(host='127.0.0.1', max_rate=-1)\n",
    "await web_ui.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9304359-c5b8-4f42-87b3-ee65af08c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_view(width=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7c6ddf-4c24-4ed2-83b0-f567c52d1b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_sim = RealTimeReplay(run=runs[\"Dummy\"][0], factor=10, web_ui=web_ui)\n",
    "await rt_sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a39ba-5df9-4306-abf3-72bd324825ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Parameters\n",
    "initial_steps_list = range(100, 200, 10)\n",
    "range_steps = 60\n",
    "min_step = 5\n",
    "# Plot divergence over time\n",
    "divergences_list = []\n",
    "fig, ax = plt.subplots(figsize=(6,2))\n",
    "for behaviour in behaviour_list:\n",
    "    for i_run in range(num_runs):\n",
    "        # Load velocities and positions\n",
    "        ps = np.array(runs[behaviour][i_run].poses)\n",
    "        twists = np.array(runs[behaviour][i_run].twists)\n",
    "        # Put together \n",
    "        # run_data = np.concatenate((ps, twists), axis=2)\n",
    "        run_data = twists\n",
    "        # Scale all variables to range from 0 to 1\n",
    "        run_data_scaled = []\n",
    "        for var_idx in range(run_data.shape[2]):\n",
    "            scaled_var = np.transpose(minmax_scale(run_data[:,:,var_idx]))\n",
    "            # scaled_var = np.transpose(run_data[:,:,var_idx]) # Omit scaling\n",
    "            run_data_scaled.append(scaled_var)\n",
    "        \n",
    "        run_data_scaled = np.array(run_data_scaled)\n",
    "        # Reorder array, putting agents on first coordinate\n",
    "        run_data_ready = []\n",
    "        for agent_id in range(run_data_scaled.shape[1]):\n",
    "            run_data_ready.append(run_data_scaled[:, agent_id, :])\n",
    "        run_data_ready = np.array(run_data_ready)\n",
    "        # Compute divergence sums for run\n",
    "        divergence_sums = []\n",
    "        initial_step = initial_steps_list[0]\n",
    "        prev_step_list = range(initial_step, initial_step + range_steps, min_step)\n",
    "        for initial_step in initial_steps_list[1:]:\n",
    "            step_list = range(initial_step, initial_step + range_steps, min_step)\n",
    "            Dist_X = distance_matrix_arrays_3D(run_data_ready[:,:,prev_step_list ], axis=0)\n",
    "            Dist_Y = distance_matrix_arrays_3D(run_data_ready[:,:,step_list] , axis=0)\n",
    "            match_diagram = perdiver.get_matching_diagram(Dist_X, Dist_Y)\n",
    "            divergence_sums.append(np.sum(np.abs(match_diagram[:,1]-match_diagram[:,0])))\n",
    "            prev_step_list = step_list\n",
    "        # Plot divergence sums\n",
    "        ax.plot(initial_steps_list[:-1], divergence_sums, color=color_behaviour[behaviour], label=behaviour)\n",
    "        divergences_list.append(divergence_sums)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.3,0),  ncol=len(behaviour_list))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c0bf07-2f49-4efd-987d-a7cccf18e9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "Y = pca.fit_transform(divergences_list)\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "for idx, behaviour in enumerate(behaviour_list):\n",
    "    ax.scatter(Y[idx*num_runs:(idx+1)*num_runs,0], Y[idx*num_runs:(idx+1)*num_runs,1], color=color_behaviour[behaviour], label=behaviour)\n",
    "\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.3,0),  ncol=len(behaviour_list))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba1112-f4bf-49d7-9f38-ec5f425f5a56",
   "metadata": {},
   "source": [
    "Use the following function from Navground documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68a5e9-c075-49b7-86fc-e4535d39d8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def count_deadlocks(deadlock_time, final_time):\n",
    "    is_deadlocked = np.logical_and(deadlock_time > 0, deadlock_time < (final_time - 5.0))\n",
    "    return sum(is_deadlocked)\n",
    "\n",
    "def extract_data(experiment):\n",
    "    collisions = []\n",
    "    deadlocks = []\n",
    "    efficacy = []\n",
    "    sms = []\n",
    "    seeds = []\n",
    "    for i, run in experiment.runs.items():\n",
    "        world = run.world\n",
    "        sm = np.unique([agent.behavior.safety_margin for agent in world.agents])\n",
    "        sms += list(sm)\n",
    "        seeds.append(run.seed)\n",
    "        final_time = run.world.time\n",
    "        deadlocks.append(count_deadlocks(np.array(run.deadlocks), final_time))\n",
    "        collisions.append(len(run.collisions))\n",
    "        efficacy.append(np.array(run.efficacy).mean())\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'seeds': seeds,\n",
    "        'safety_margin': sms,\n",
    "        'deadlocks': deadlocks,\n",
    "        'collisions': collisions,\n",
    "        'efficacy': efficacy})\n",
    "    df['safe'] = (df.collisions == 0).astype(int)\n",
    "    df['fluid'] = (df.deadlocks == 0).astype(int)\n",
    "    df['ok'] = ((df.deadlocks == 0) & (df.collisions == 0)).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b057a13a-53b4-4f74-ba86-b6448e4f4c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "deadlocks_list = []\n",
    "collisions_list = []\n",
    "efficacy_list = []\n",
    "for behaviour in behaviour_list:\n",
    "    path = f\"experiment_matching_finer_{behaviour}.h5\"\n",
    "    recorded_experiment = sim.RecordedExperiment(path)\n",
    "    df = extract_data(recorded_experiment)\n",
    "    collisions_list += list(df.collisions)\n",
    "    deadlocks_list += list(df.deadlocks)\n",
    "    efficacy_list += list(df.efficacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ea292a-cf1d-4803-bd4f-752672b99e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3)\n",
    "# Plot PCA of points using divergences sums\n",
    "for idx, behaviour in enumerate(behaviour_list):\n",
    "    ax.scatter(Y[idx*num_runs:(idx+1)*num_runs,0], Y[idx*num_runs:(idx+1)*num_runs,1], color=color_behaviour[behaviour], label=behaviour)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "# Efficacy \n",
    "for idx, behaviour in enumerate(behaviour_list):\n",
    "    ax.scatter(Y[idx*num_runs:(idx+1)*num_runs,0], Y[idx*num_runs:(idx+1)*num_runs,1], color=color_behaviour[behaviour], label=behaviour)\n",
    "\n",
    "\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0.3,0),  ncol=len(behaviour_list))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52111da2-8863-4015-92d8-c22905011c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficacy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5357f-77e9-4833-a6f1-5a613e673e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.colormaps[\"Greens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679c9b58-7579-44db-9cab-23f6a55317c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = np.vstack((np.array([efficacy_list]), np.array([collisions_list]))).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489511c-f517-44b3-aee2-2fe6b2d5871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "for idx, behaviour in enumerate(behaviour_list):\n",
    "    points_beh = points[idx*num_runs:(idx+1)*num_runs]\n",
    "    ax.scatter(points_beh[:,0], points_beh[:,1], color=color_behaviour[behaviour], label=behaviour)\n",
    "# end for\n",
    "ax.set_xlabel(\"efficacy\")\n",
    "ax.set_ylabel(\"collisions\")\n",
    "fig.legend(by_label.values(), by_label.keys(), loc=(0,0),  ncol=len(behaviour_list))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88a6405-9c3f-412c-809b-9b8ab34f0461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
